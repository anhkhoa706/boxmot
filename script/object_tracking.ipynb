{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 408M\n",
      "-rw-rw-r-- 1 wins057 wins057  80M  äº”  23 17:38 yolov10b.pt\n",
      "-rw-rw-r-- 1 wins057 wins057 100M  äº”  23 17:38 yolov10l.pt\n",
      "-rw-rw-r-- 1 wins057 wins057  64M  äº”  23 17:38 yolov10m.pt\n",
      "-rw-rw-r-- 1 wins057 wins057  11M  äº”  23 17:38 yolov10n.pt\n",
      "-rw-rw-r-- 1 wins057 wins057  32M  äº”  23 17:38 yolov10s.pt\n",
      "-rw-rw-r-- 1 wins057 wins057 123M  äº”  23 17:38 yolov10x.pt\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/THU-MIG/yolov10.git\n",
    "!mkdir -p weights\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10s.pt\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10m.pt\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10b.pt\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10x.pt\n",
    "!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10l.pt\n",
    "!ls -lh weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install boxmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wins057/Documents/Projects/ReID/YOLOv10/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from boxmot import DeepOCSORT, BoTSORT, StrongSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_writer(video_cap, output_filename):\n",
    "    # Grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-05 12:21:34.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboxmot.utils.torch_utils\u001b[0m:\u001b[36mselect_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mYolo Tracking v11.0.0 ðŸš€ Python-3.10.12 torch-2.2.2+cu121\n",
      "CUDA:0 (NVIDIA GeForce RTX 3090, 24145MiB)\u001b[0m\n",
      "\u001b[32m2024-12-05 12:21:35.821\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m183\u001b[0m - \u001b[32m\u001b[1mLoaded pretrained weights from weights_ReID/pt/Market1501_clipreid_RN50_120.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized position embedding: %s to %s torch.Size([197, 768]) torch.Size([129, 768])\n",
      "Position embedding resize to height:16 width: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- []\n",
      "----- [[     1718.3      61.357      1746.4      172.85           1     0.71241           0           0]]\n",
      "----- [[     1703.8      61.286      1742.9      171.62           1      0.7913           0           0]]\n",
      "----- [[     1692.1      61.807      1743.7      173.45           1     0.82965           0           0]]\n",
      "----- [[     1685.5      62.112      1742.5      175.81           1     0.82632           0           0]]\n",
      "----- [[     1683.3       60.66      1733.1      172.56           1     0.82478           0           0]]\n",
      "----- [[     1682.6      59.704      1718.9      170.91           1     0.79399           0           0]]\n",
      "----- [[       1674      58.779      1707.2      167.28           1     0.82931           0           0]]\n",
      "----- [[       1662      58.575      1702.6      167.55           1     0.88145           0           0]]\n",
      "----- [[     1650.8       59.31      1700.4      168.41           1     0.86645           0           0]]\n",
      "----- [[     1647.2      58.972      1694.7      168.29           1     0.80576           0           0]]\n",
      "----- [[     1646.2      56.934      1684.6       168.2           1     0.77307           0           0]]\n",
      "----- []\n",
      "----- [[     1713.8      67.569      1746.3      176.45           2     0.54305           0           0]]\n",
      "----- [[     1700.5      67.517      1733.7      173.29           2     0.70071           0           0]]\n",
      "----- [[     1687.9      67.761      1732.3       173.6           2     0.76286           0           0]]\n",
      "----- [[     1681.4      66.024      1728.3      172.28           2     0.67241           0           0]]\n",
      "----- [[     1678.4      64.663      1719.7      168.23           2     0.70315           0           0]]\n",
      "----- [[     1672.4      63.626      1705.3      169.62           2     0.69681           0           0]]\n",
      "----- [[     1660.4      62.497      1700.3      168.54           2     0.80808           0           0]]\n",
      "----- [[     1651.2      63.393        1697      168.27           2     0.76574           0           0]]\n",
      "----- [[       1648      62.886      1693.6      171.69           2     0.63189           0           0]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tracker\n",
    "reid_weights_path = Path('weights_ReID/pt/Market1501_clipreid_RN50_120.pt')\n",
    "tracker = BoTSORT(\n",
    "    reid_weights = reid_weights_path,  # which ReID model to use\n",
    "    device = 'cuda:0',\n",
    "    half = False\n",
    ")\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO('weights/yolov10x.pt')\n",
    "\n",
    "# Open the input video\n",
    "# input_video_path = 'videos/05_1F_2024_9_2_8mins.mp4'\n",
    "input_video_path = 'videos/32_1F_2024_9_2_part2.mp4'\n",
    "vid = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    print(\"Error: Could not open input video.\")\n",
    "    exit()\n",
    "\n",
    "# Define the output video path\n",
    "output_video_path = 'videos/32_1F_2024_9_2_part2_tracking.mp4'\n",
    "\n",
    "# Create the video writer\n",
    "out = create_video_writer(vid, output_video_path)\n",
    "\n",
    "# Confidence threshold for filtering low-confidence detections\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "images = []\n",
    "while True:\n",
    "    ret, im = vid.read()\n",
    "    if not ret:\n",
    "        print(\"End of video reached or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "      # Run the YOLO model on the frame - detect person only\n",
    "      results = model(im, classes=[0], verbose=False)\n",
    "      # print(results[0])\n",
    "\n",
    "      if len(results) >= 1:\n",
    "        # Convert the detections to the required format: N X (x, y, x, y, conf, cls)\n",
    "        dets = []\n",
    "        for result in results:\n",
    "          for boxes in result.boxes:\n",
    "            conf = boxes.conf.item() # Get the confidence score\n",
    "            if conf >= CONFIDENCE_THRESHOLD: # Filter based on confidence threshold\n",
    "              # Extract bounding box coordinates\n",
    "              x1, y1, x2, y2 = boxes.xyxy[0][0].item(), boxes.xyxy[0][1].item(), boxes.xyxy[0][2].item(), boxes.xyxy[0][3].item()\n",
    "              cls = boxes.cls.item()\n",
    "              dets.append([x1, y1, x2, y2, conf, int(cls)])\n",
    "        dets = np.array(dets)\n",
    "\n",
    "        # Check if there are any detections\n",
    "        if dets.size > 0:\n",
    "            # Update the tracker with the detections\n",
    "            print(\"-----\", tracker.update(dets, im)) # --> M X (x, y, x, y, id, conf, cls, ind)\n",
    "        # If no detections, make prediction ahead\n",
    "        else:\n",
    "            dets = np.empty((0, 6))  # empty N X (x, y, x, y, conf, cls)\n",
    "            tracker.update(dets, im) # --> M X (x, y, x, y, id, conf, cls, ind)\n",
    "\n",
    "        # Plot results on the frame\n",
    "        tracker.plot_results(im, show_trajectories=True)\n",
    "\n",
    "      # Write the frame to the output video\n",
    "      images.append(im)\n",
    "      out.write(im)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Tracking video saved to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
